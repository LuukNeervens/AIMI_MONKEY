{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17eb284a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imagecodecs\n",
      "  Using cached imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from imagecodecs) (1.23.5)\n",
      "Installing collected packages: imagecodecs\n",
      "Successfully installed imagecodecs-2025.3.30\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imagecodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8eb89aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting affine (from rasterio)\n",
      "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.11/site-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/site-packages (from rasterio) (2023.5.7)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/site-packages (from rasterio) (8.1.3)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Collecting numpy>=1.24 (from rasterio)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting click-plugins (from rasterio)\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/site-packages (from rasterio) (3.0.9)\n",
      "Installing collected packages: numpy, cligj, click-plugins, affine, rasterio\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-model-optimization 0.7.4 requires numpy~=1.23, but you have numpy 2.2.6 which is incompatible.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 numpy-2.2.6 rasterio-1.4.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b39c6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting packaging>=20.0 (from matplotlib)\n",
      "  Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m687.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dateutil>=2.7 (from matplotlib)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m599.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.7->matplotlib)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, pyparsing, pillow, packaging, numpy, kiwisolver, fonttools, cycler, python-dateutil, contourpy, matplotlib\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.5.0\n",
      "    Uninstalling Pillow-9.5.0:\n",
      "      Successfully uninstalled Pillow-9.5.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.4\n",
      "    Uninstalling kiwisolver-1.4.4:\n",
      "      Successfully uninstalled kiwisolver-1.4.4\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.39.4\n",
      "    Uninstalling fonttools-4.39.4:\n",
      "      Successfully uninstalled fonttools-4.39.4\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.0.7\n",
      "    Uninstalling contourpy-1.0.7:\n",
      "      Successfully uninstalled contourpy-1.0.7\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.1\n",
      "    Uninstalling matplotlib-3.7.1:\n",
      "      Successfully uninstalled matplotlib-3.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-model-optimization 0.7.4 requires numpy~=1.23, but you have numpy 2.2.6 which is incompatible.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.2.6 which is incompatible.\n",
      "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 numpy-2.2.6 packaging-25.0 pillow-11.2.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 six-1.17.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade --force-reinstall numpy matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee424af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a892526",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9944e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "import openslide\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import models, transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0a76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "happiny_folder = Path(\"/data/temporary/archives/lung/generator/MONKEY_challenge\")\n",
    "orig_dir = happiny_folder / \"images/pas-original\"\n",
    "cpg_dir = happiny_folder / \"images/pas-cpg\"\n",
    "diagnostic_dir = happiny_folder / \"images/pas-diagnostic\"\n",
    "xml_dir = happiny_folder / \"annotations/xml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec236bf",
   "metadata": {},
   "source": [
    "# Extracting patches from ROIs from the train dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3110764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 81 inflammatory cell JSON files\n",
      "\n",
      "Processing modality: pas-original\n",
      "  ⚠️ No TIFF file found for sample ID P000021 in pas-original\n",
      "  ⚠️ No TIFF file found for sample ID P000021 in pas-original\n",
      "  Using D_P000019_PAS_Original.tif with 10 ROIs\n",
      "  Using D_P000016_PAS_Original.tif with 10 ROIs\n",
      "  Using D_P000003_PAS_Original.tif with 10 ROIs\n",
      "  Using B_P000020_PAS_Original.tif with 10 ROIs\n",
      "  Using D_P000002_PAS_Original.tif with 10 ROIs\n",
      "  ⚠️ No TIFF file found for sample ID P000033 in pas-original\n",
      "  Using D_P000006_PAS_Original.tif with 10 ROIs\n",
      "  Using D_P000002_PAS_Original.tif with 10 ROIs\n",
      "\n",
      "Processing modality: pas-cpg\n",
      "  Using A_P000021_PAS_CPG.tif with 10 ROIs\n",
      "  Using A_P000021_PAS_CPG.tif with 10 ROIs\n",
      "  Using D_P000019_PAS_CPG.tif with 10 ROIs\n",
      "  Using D_P000016_PAS_CPG.tif with 10 ROIs\n",
      "  Using B_P000003_PAS_CPG.tif with 10 ROIs\n",
      "  Using A_P000020_PAS_CPG.tif with 10 ROIs\n",
      "  Using D_P000002_PAS_CPG.tif with 10 ROIs\n",
      "  Using A_P000033_PAS_CPG.tif with 10 ROIs\n",
      "  Using D_P000006_PAS_CPG.tif with 10 ROIs\n",
      "  Using D_P000002_PAS_CPG.tif with 10 ROIs\n",
      "\n",
      "Processing modality: pas-diagnostic\n",
      "  Using A_P000021_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using A_P000021_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using D_P000019_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using B_P000016_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using D_P000003_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using B_P000020_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using B_P000002_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using C_P000033_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using D_P000006_PAS_Diagnostic.tif with 10 ROIs\n",
      "  Using B_P000002_PAS_Diagnostic.tif with 10 ROIs\n",
      "\n",
      "✅ Patch extraction complete.\n"
     ]
    }
   ],
   "source": [
    "PATCH_SIZE = 256\n",
    "NUM_JSONS = 10\n",
    "NUM_PATCHES_PER_FILE = 10\n",
    "\n",
    "happiny_folder = Path(\"/data/temporary/archives/lung/generator/MONKEY_challenge\")\n",
    "json_pixel_dir = happiny_folder / \"annotations/json_pix\"\n",
    "PATCHES_DIR = happiny_folder / \"patches\"  \n",
    "modalities = {\n",
    "    \"pas-original\": happiny_folder / \"images/pas-original\",\n",
    "    \"pas-cpg\": happiny_folder / \"images/pas-cpg\",\n",
    "    \"pas-diagnostic\": happiny_folder / \"images/pas-diagnostic\",\n",
    "}\n",
    "\n",
    "PATCHES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_sample_id(json_path):\n",
    "    match = re.search(r'P\\d{6}', json_path.name)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def load_json_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return [(int(p[\"point\"][0]), int(p[\"point\"][1])) for p in data.get(\"points\", [])]\n",
    "\n",
    "def extract_patch(tif_path, center_x, center_y, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    xmin = max(center_x - half, 0)\n",
    "    ymin = max(center_y - half, 0)\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        max_width, max_height = src.width, src.height\n",
    "        xmin = min(xmin, max_width - patch_size)\n",
    "        ymin = min(ymin, max_height - patch_size)\n",
    "        window = Window(xmin, ymin, patch_size, patch_size)\n",
    "        patch = src.read(window=window)\n",
    "        patch = np.transpose(patch, (1, 2, 0))  # (H, W, C)\n",
    "    return patch\n",
    "\n",
    "def save_selected_patches():\n",
    "    json_files = list(json_pixel_dir.glob(\"*inflammatory-cells.json\"))\n",
    "    print(f\"🔍 Found {len(json_files)} inflammatory cell JSON files\")\n",
    "\n",
    "    # Randomly sample JSON files without replacement\n",
    "    json_files_sampled = random.sample(json_files, min(NUM_JSONS, len(json_files)))\n",
    "\n",
    "    for modality, tif_dir in modalities.items():\n",
    "        output_dir = PATCHES_DIR / modality\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"\\nProcessing modality: {modality}\")\n",
    "\n",
    "        for json_file in json_files_sampled:\n",
    "            coords = load_json_annotations(json_file)[:NUM_PATCHES_PER_FILE]\n",
    "            sample_id = get_sample_id(json_file)\n",
    "            if not sample_id:\n",
    "                continue\n",
    "\n",
    "            tif_matches = list(tif_dir.glob(f\"*{sample_id}*.tif\"))\n",
    "            if not tif_matches:\n",
    "                print(f\"  ⚠️ No TIFF file found for sample ID {sample_id} in {modality}\")\n",
    "                continue\n",
    "\n",
    "            tif_path = tif_matches[0]  # Take the first match\n",
    "            print(f\"  Using {tif_path.name} with {len(coords)} ROIs\")\n",
    "\n",
    "            for i, (x, y) in enumerate(coords):\n",
    "                try:\n",
    "                    patch = extract_patch(tif_path, x, y, PATCH_SIZE)\n",
    "                    patch_img = Image.fromarray(patch.astype(np.uint8))\n",
    "                    patch_name = f\"{sample_id}_patch{i}.png\"\n",
    "                    patch_img.save(output_dir / patch_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"    ⚠️ Failed to extract patch {i} at ({x},{y}): {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_selected_patches()\n",
    "    print(\"\\n✅ Patch extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0d452",
   "metadata": {},
   "source": [
    "# Extracting patches from ROIs from the test dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9516d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81 inflammatory-cells JSON files\n",
      "Processing B_P000001_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000006_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000018_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000020_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000021_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000022_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000024_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000029_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000030_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000031_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000032_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000033_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000034_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000035_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000036_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000037_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000038_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000001_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000009_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000010_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000012_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000013_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000015_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000019_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000020_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000021_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000022_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000023_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000024_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000025_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000026_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000027_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000028_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000029_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000030_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000031_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000032_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000033_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000034_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000035_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000036_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000037_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000038_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000039_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing C_P000040_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000001_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000006_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000009_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000010_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000012_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000013_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing B_P000015_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing A_P000018_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Processing D_P000019_PAS_CPG.tif with 5 inflammatory-cells ROIs\n",
      "Found 81 lymphocytes JSON files\n",
      "Processing B_P000001_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000006_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000018_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000020_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000021_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000022_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000024_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000029_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000030_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000031_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000032_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000033_PAS_CPG.tif with 4 lymphocytes ROIs\n",
      "Processing C_P000034_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000035_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000036_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000037_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000038_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000001_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000009_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000010_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000012_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000013_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000015_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000019_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000020_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000021_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000022_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000023_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000024_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000025_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000026_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000027_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000028_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000029_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000030_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000031_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000032_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000033_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000034_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000035_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000036_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000037_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000038_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000039_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing C_P000040_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000001_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000006_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000009_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000010_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000012_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000013_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing B_P000015_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing A_P000018_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Processing D_P000019_PAS_CPG.tif with 5 lymphocytes ROIs\n",
      "Found 81 monocytes JSON files\n",
      "Processing B_P000001_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000006_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000018_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000020_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000021_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000022_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000024_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000029_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000030_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000031_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000032_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000033_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000034_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000035_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000036_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000037_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000038_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000001_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000009_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000010_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000012_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000013_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000015_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000019_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000020_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000021_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000022_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000023_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000024_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000025_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000026_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000027_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000028_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000029_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000030_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000031_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000032_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000033_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000034_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000035_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000036_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000037_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000038_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000039_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing C_P000040_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000001_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000002_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000003_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000004_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000005_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000006_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000007_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000009_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000010_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000011_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000012_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000013_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000014_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing B_P000015_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000016_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000017_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing A_P000018_PAS_CPG.tif with 5 monocytes ROIs\n",
      "Processing D_P000019_PAS_CPG.tif with 5 monocytes ROIs\n",
      "✅ Finished extracting cpg patches for inflammatory, lymphocytes, and monocytes.\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "PATCH_SIZE = 256\n",
    "NUM_PATCHES_PER_FILE = 5\n",
    "\n",
    "# Paths\n",
    "happiny_folder = Path(\"/data/temporary/archives/lung/generator/MONKEY_challenge\")\n",
    "json_pixel_dir = happiny_folder / \"annotations/json_pix\"\n",
    "PATCHES_DIR = happiny_folder / \"patches\"\n",
    "\n",
    "cpg_dir = happiny_folder / \"images/pas-cpg\"\n",
    "\n",
    "# Create output directories for cpg modalities + cell types\n",
    "for cell_type in [\"inflammatory-cells\", \"lymphocytes\", \"monocytes\"]:\n",
    "    (PATCHES_DIR / \"cpg\" / cell_type).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Helpers\n",
    "def get_sample_id(json_path):\n",
    "    match = re.search(r'P\\d{6}', json_path.name)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "def load_json_annotations(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return [(int(p[\"point\"][0]), int(p[\"point\"][1])) for p in data.get(\"points\", [])]\n",
    "\n",
    "def extract_patch(tif_path, center_x, center_y, patch_size=PATCH_SIZE):\n",
    "    half = patch_size // 2\n",
    "    xmin = max(center_x - half, 0)\n",
    "    ymin = max(center_y - half, 0)\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        max_width, max_height = src.width, src.height\n",
    "        xmin = min(xmin, max_width - patch_size)\n",
    "        ymin = min(ymin, max_height - patch_size)\n",
    "        window = Window(xmin, ymin, patch_size, patch_size)\n",
    "        patch = src.read(window=window)\n",
    "        patch = np.transpose(patch, (1, 2, 0))  # (H, W, C)\n",
    "    return patch\n",
    "\n",
    "def save_cpg_patches_for_cell_types():\n",
    "    # Cell types to process\n",
    "    cell_types = [\"inflammatory-cells\", \"lymphocytes\", \"monocytes\"]\n",
    "    \n",
    "    # For each cell type, find relevant json files\n",
    "    for cell_type in cell_types:\n",
    "        json_files = sorted(json_pixel_dir.glob(f\"*{cell_type}.json\"))\n",
    "        print(f\"Found {len(json_files)} {cell_type} JSON files\")\n",
    "\n",
    "        for json_file in json_files:\n",
    "            coords = load_json_annotations(json_file)[:NUM_PATCHES_PER_FILE]\n",
    "            sample_id = get_sample_id(json_file)\n",
    "            if not sample_id:\n",
    "                continue\n",
    "\n",
    "            tif_matches = list(cpg_dir.glob(f\"*{sample_id}*.tif\"))\n",
    "            if not tif_matches:\n",
    "                continue\n",
    "\n",
    "            tif_path = tif_matches[0]  # Use the first match\n",
    "            print(f\"Processing {tif_path.name} with {len(coords)} {cell_type} ROIs\")\n",
    "\n",
    "            output_dir = PATCHES_DIR / \"cpg\" / cell_type\n",
    "\n",
    "            for i, (x, y) in enumerate(coords):\n",
    "                patch = extract_patch(tif_path, x, y, PATCH_SIZE)\n",
    "                patch_img = Image.fromarray(patch.astype(np.uint8))\n",
    "                patch_name = f\"{sample_id}_{cell_type}_patch{i}.png\"\n",
    "                patch_img.save(output_dir / patch_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_cpg_patches_for_cell_types()\n",
    "    print(\"✅ Finished extracting cpg patches for inflammatory, lymphocytes, and monocytes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6321055",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = [\n",
    "    PATCHES_DIR / \"pas-original\",\n",
    "    PATCHES_DIR / \"pas-diagnostic\"\n",
    "]\n",
    "test_dirs = [\n",
    "    PATCHES_DIR / \"cpg\" / \"inflammatory-cells\",\n",
    "    PATCHES_DIR / \"cpg\" / \"monocytes\",\n",
    "    PATCHES_DIR / \"cpg\" / \"lymphocytes\"\n",
    "]\n",
    "cpg_inflammatory_dir = PATCHES_DIR / \"cpg\" / \"inflammatory-cells\"\n",
    "\n",
    "class_names_all = [\"inflammatory-cells\", \"monocytes\", \"lymphocytes\"]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def wrap_with_label_folder(path, label=\"dummy\"):\n",
    "    temp = path.parent / f\"{path.name}_wrapped\"\n",
    "    temp.mkdir(exist_ok=True)\n",
    "    label_path = temp / label\n",
    "    label_path.mkdir(exist_ok=True)\n",
    "    for img in path.glob(\"*.png\"):\n",
    "        symlink = label_path / img.name\n",
    "        if not symlink.exists():\n",
    "            symlink.symlink_to(img)\n",
    "    return temp\n",
    "\n",
    "# Create dataloaders from directories\n",
    "def create_dataloader(dirs, transform, batch_size=32, shuffle=True):\n",
    "    wrapped_dirs = [wrap_with_label_folder(d) for d in dirs]\n",
    "    datasets_list = [datasets.ImageFolder(d, transform=transform) for d in wrapped_dirs]\n",
    "    combined_dataset = ConcatDataset(datasets_list)\n",
    "    loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "# Extract features for a given dataset loader and encoder model\n",
    "def extract_features(encoder, loader, device):\n",
    "    encoder.eval()\n",
    "    all_feats = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = encoder(imgs).cpu()\n",
    "            all_feats.append(feats)\n",
    "            all_labels.append(labels)\n",
    "    X = torch.cat(all_feats).numpy()\n",
    "    y = torch.cat(all_labels).numpy()\n",
    "    return X, y\n",
    "\n",
    "# Pretrain encoder on train_dirs (pas-original + pas-diagnostic)\n",
    "def pretrain_encoder(train_dirs, transform, device, epochs=5):\n",
    "    train_loader = create_dataloader(train_dirs, transform, batch_size=32, shuffle=True)\n",
    "    encoder = models.resnet18(pretrained=True)\n",
    "    encoder.fc = nn.Identity()  \n",
    "    encoder = encoder.to(device)\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "    encoder.train()\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, _ in tqdm(train_loader, desc=f\"Pretraining Epoch {epoch+1}\"):\n",
    "            imgs = imgs.to(device)\n",
    "            features = encoder(imgs)\n",
    "            loss = features.norm(dim=1).mean() \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return encoder\n",
    "\n",
    "# Fine-tune encoder on only CPG inflammatory-cells (binary classification)\n",
    "def finetune_on_cpg_inflammatory(encoder, cpg_dir, transform, device, epochs=3):\n",
    "    # Prepare dataset with label 0 for inflammatory cells (binary classification)\n",
    "    wrapped_dir = wrap_with_label_folder(cpg_dir, label=\"inflammatory-cells\")\n",
    "    dataset = datasets.ImageFolder(wrapped_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    # Add classification head for binary classification\n",
    "    encoder.fc = nn.Linear(512, 2)\n",
    "    encoder = encoder.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "    \n",
    "    encoder.train()\n",
    "    for epoch in range(epochs):\n",
    "        for imgs, labels in tqdm(loader, desc=f\"Fine-tuning CPG inflammatory Epoch {epoch+1}\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = encoder(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return encoder\n",
    "\n",
    "# Prepare test dataloader for all CPG classes with correct labels\n",
    "def create_cpg_test_loader(test_dirs, transform, batch_size=32):\n",
    "    wrapped_dirs = []\n",
    "    for i, d in enumerate(test_dirs):\n",
    "        wrapped_dirs.append(wrap_with_label_folder(d, label=str(i)))  # label folder name = class index\n",
    "    datasets_list = [datasets.ImageFolder(d, transform=transform) for d in wrapped_dirs]\n",
    "    combined_dataset = ConcatDataset(datasets_list)\n",
    "    loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "# Extract features with fine-tuned encoder for multi-class classification\n",
    "def extract_features_multiclass(encoder, loader, device):\n",
    "    encoder.eval()\n",
    "    all_feats = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            feats = encoder(imgs)\n",
    "            all_feats.append(feats.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    X = torch.cat(all_feats).numpy()\n",
    "    y = torch.cat(all_labels).numpy()\n",
    "    return X, y\n",
    "\n",
    "# --------- MAIN PIPELINE ---------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model A: Pretrain encoder on pas-original + pas-diagnostic only\n",
    "print(\"Pretraining encoder (Model A)...\")\n",
    "encoder_A = pretrain_encoder(train_dirs, transform, device)\n",
    "\n",
    "# Test Model A on all CPG classes with RF classifier on frozen encoder features\n",
    "print(\"\\nEvaluating Model A (no fine-tuning on CPG)...\")\n",
    "cpg_test_loader = create_cpg_test_loader(test_dirs, transform, batch_size=32)\n",
    "X_A, y_A = extract_features(encoder_A, cpg_test_loader, device)\n",
    "\n",
    "clf_A = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_A.fit(X_A, y_A)\n",
    "y_pred_A = clf_A.predict(X_A)\n",
    "\n",
    "print(\"Model A Confusion Matrix:\")\n",
    "print(confusion_matrix(y_A, y_pred_A))\n",
    "print(\"Model A Classification Report:\")\n",
    "print(classification_report(y_A, y_pred_A, target_names=class_names_all))\n",
    "\n",
    "# Model B: Fine-tune encoder on CPG inflammatory-cells (binary) \n",
    "print(\"\\nFine-tuning encoder on CPG inflammatory-cells (Model B)...\")\n",
    "encoder_B = finetune_on_cpg_inflammatory(encoder_A, cpg_inflammatory_dir, transform, device, epochs=3)\n",
    "\n",
    "# For Model B testing, remove classification head for feature extraction (to get embeddings)\n",
    "encoder_B.fc = nn.Identity()\n",
    "encoder_B = encoder_B.to(device)\n",
    "\n",
    "# Extract features from all CPG classes with fine-tuned encoder\n",
    "print(\"\\nEvaluating Model B (fine-tuned on CPG inflammatory-cells)...\")\n",
    "X_B, y_B = extract_features(encoder_B, cpg_test_loader, device)\n",
    "\n",
    "clf_B = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_B.fit(X_B, y_B)\n",
    "y_pred_B = clf_B.predict(X_B)\n",
    "\n",
    "print(\"Model B Confusion Matrix:\")\n",
    "print(confusion_matrix(y_B, y_pred_B))\n",
    "print(\"Model B Classification Report:\")\n",
    "print(classification_report(y_B, y_pred_B, target_names=class_names_all))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
